{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4espuLKJiA"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DjZQV2njKJ3U"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTL0TERThT6z"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/audio/transfer_learning_audio\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/audio/transfer_learning_audio.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/audio/transfer_learning_audio.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/google/yamnet/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2madPFAGHb3"
      },
      "source": [
        "# Transfer learning with YAMNet for environmental sound classification\n",
        "\n",
        "[YAMNet](https://tfhub.dev/google/yamnet/1) is a pre-trained deep neural network that can predict audio events from [521 classes](https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv), such as laughter, barking, or a siren. \n",
        "\n",
        " In this tutorial you will learn how to:\n",
        "\n",
        "- Load and use the YAMNet model for inference.\n",
        "- Build a new model using the YAMNet embeddings to classify cat and dog sounds.\n",
        "- Evaluate and export your model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mdp2TpBh96Y"
      },
      "source": [
        "## Import TensorFlow and other libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCcKYqu_hvKe"
      },
      "source": [
        "Start by installing [TensorFlow I/O](https://www.tensorflow.org/io), which will make it easier for you to load audio files off disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urBpRWDHTHHU"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"tensorflow==2.11.*\"\n",
        "# tensorflow_io 0.28 is compatible with TensorFlow 2.11\n",
        "!pip install -q \"tensorflow_io==0.28.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l3nqdWVF-kC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ZhybCnt_bM"
      },
      "source": [
        "## About YAMNet\n",
        "\n",
        "[YAMNet](https://github.com/tensorflow/models/tree/master/research/audioset/yamnet) is a pre-trained neural network that employs the [MobileNetV1](https://arxiv.org/abs/1704.04861) depthwise-separable convolution architecture. It can use an audio waveform as input and make independent predictions for each of the 521 audio events from the [AudioSet](http://g.co/audioset) corpus.\n",
        "\n",
        "Internally, the model extracts \"frames\" from the audio signal and processes batches of these frames. This version of the model uses frames that are 0.96 second long and extracts one frame every 0.48 seconds .\n",
        "\n",
        "The model accepts a 1-D float32 Tensor or NumPy array containing a waveform of arbitrary length, represented as single-channel (mono) 16 kHz samples in the range `[-1.0, +1.0]`. This tutorial contains code to help you convert WAV files into the supported format.\n",
        "\n",
        "The model returns 3 outputs, including the class scores, embeddings (which you will use for transfer learning), and the log mel [spectrogram](https://www.tensorflow.org/tutorials/audio/simple_audio#spectrogram). You can find more details [here](https://tfhub.dev/google/yamnet/1).\n",
        "\n",
        "One specific use of YAMNet is as a high-level feature extractor - the 1,024-dimensional embedding output. You will use the base (YAMNet) model's input features and feed them into your shallower model consisting of one hidden `tf.keras.layers.Dense` layer. Then, you will train the network on a small amount of data for audio classification _without_ requiring a lot of labeled data and training end-to-end. (This is similar to [transfer learning for image classification with TensorFlow Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) for more information.)\n",
        "\n",
        "First, you will test the model and see the results of classifying audio. You will then construct the data pre-processing pipeline.\n",
        "\n",
        "### Loading YAMNet from TensorFlow Hub\n",
        "\n",
        "You are going to use a pre-trained YAMNet from [Tensorflow Hub](https://tfhub.dev/) to extract the embeddings from the sound files.\n",
        "\n",
        "Loading a model from TensorFlow Hub is straightforward: choose the model, copy its URL, and use the `load` function.\n",
        "\n",
        "Note: to read the documentation of the model, use the model URL in your browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06CWkBV5v3gr"
      },
      "outputs": [],
      "source": [
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet_model = hub.load(yamnet_model_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmrPJ0GHw9rr"
      },
      "source": [
        "With the model loaded, you can follow the [YAMNet basic usage tutorial](https://www.tensorflow.org/hub/tutorials/yamnet) and download a sample WAV file to run the inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5i6xktEq00P"
      },
      "outputs": [],
      "source": [
        "testing_wav_file_name = tf.keras.utils.get_file('miaow_16k.wav',\n",
        "                                                'https://storage.googleapis.com/audioset/miaow_16k.wav',\n",
        "                                                cache_dir='./',\n",
        "                                                cache_subdir='test_data')\n",
        "\n",
        "print(testing_wav_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBm9y9iV2U_-"
      },
      "source": [
        "You will need a function to load audio files, which will also be used later when working with the training data. (Learn more about reading audio files and their labels in [Simple audio recognition](https://www.tensorflow.org/tutorials/audio/simple_audio#reading_audio_files_and_their_labels).\n",
        "\n",
        "Note: The returned `wav_data` from `load_wav_16k_mono` is already normalized to values in the `[-1.0, 1.0]` range (for more information, go to [YAMNet's documentation on TF Hub](https://tfhub.dev/google/yamnet/1))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwc9Wrdg2EtY"
      },
      "outputs": [],
      "source": [
        "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
        "\n",
        "@tf.function\n",
        "def load_wav_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    wav, sample_rate = tf.audio.decode_wav(\n",
        "          file_contents,\n",
        "          desired_channels=1)\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRqpjkwB0Jjw"
      },
      "outputs": [],
      "source": [
        "testing_wav_data = load_wav_16k_mono(testing_wav_file_name)\n",
        "\n",
        "_ = plt.plot(testing_wav_data)\n",
        "\n",
        "# Play the audio file.\n",
        "display.Audio(testing_wav_data, rate=16000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z6rqlEz20YB"
      },
      "source": [
        "### Load the class mapping\n",
        "\n",
        "It's important to load the class names that YAMNet is able to recognize. The mapping file is present at `yamnet_model.class_map_path()` in the CSV format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gyj23e_3Mgr"
      },
      "outputs": [],
      "source": [
        "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
        "class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
        "\n",
        "for name in class_names[:20]:\n",
        "  print(name)\n",
        "print('...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xbycDnT40u0"
      },
      "source": [
        "### Run inference\n",
        "\n",
        "YAMNet provides frame-level class-scores (i.e., 521 scores for every frame). In order to determine clip-level predictions, the scores can be aggregated per-class across frames (e.g., using mean or max aggregation). This is done below by `scores_np.mean(axis=0)`. Finally, to find the top-scored class at the clip-level, you take the maximum of the 521 aggregated scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT0otp-A4Y3u"
      },
      "outputs": [],
      "source": [
        "scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
        "class_scores = tf.reduce_mean(scores, axis=0)\n",
        "top_class = tf.math.argmax(class_scores)\n",
        "inferred_class = class_names[top_class]\n",
        "\n",
        "print(f'The main sound is: {inferred_class}')\n",
        "print(f'The embeddings shape: {embeddings.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBaLNg5H5IWa"
      },
      "source": [
        "Note: The model correctly inferred an animal sound. Your goal in this tutorial is to increase the model's accuracy for specific classes. Also, notice that the model generated 13 embeddings, 1 per frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmthELBg1A2-"
      },
      "source": [
        "## ESC-50 dataset\n",
        "\n",
        "The [ESC-50 dataset](https://github.com/karolpiczak/ESC-50#repository-content) ([Piczak, 2015](https://www.karolpiczak.com/papers/Piczak2015-ESC-Dataset.pdf)) is a labeled collection of 2,000 five-second long environmental audio recordings. The dataset consists of 50 classes, with 40 examples per class.\n",
        "\n",
        "Download the dataset and extract it. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWobqK8JmZOU"
      },
      "outputs": [],
      "source": [
        "_ = tf.keras.utils.get_file('esc-50.zip',\n",
        "                        'https://github.com/karoldvl/ESC-50/archive/master.zip',\n",
        "                        cache_dir='./',\n",
        "                        cache_subdir='datasets',\n",
        "                        extract=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcruxiuX1cO5"
      },
      "source": [
        "### Explore the data\n",
        "\n",
        "The metadata for each file is specified in the csv file at `./datasets/ESC-50-master/meta/esc50.csv`\n",
        "\n",
        "and all the audio files are in `./datasets/ESC-50-master/audio/`\n",
        "\n",
        "You will create a pandas `DataFrame` with the mapping and use that to have a clearer view of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwmLygPrMAbH"
      },
      "outputs": [],
      "source": [
        "esc50_csv = './datasets/ESC-50-master/meta/esc50.csv'\n",
        "base_data_path = './datasets/ESC-50-master/audio/'\n",
        "\n",
        "pd_data = pd.read_csv(esc50_csv)\n",
        "pd_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4rHBEQ2QAU"
      },
      "source": [
        "### Filter the data\n",
        "\n",
        "Now that the data is stored in the `DataFrame`, apply some transformations:\n",
        "\n",
        "- Filter out rows and use only the selected classes - `dog` and `cat`. If you want to use any other classes, this is where you can choose them.\n",
        "- Amend the filename to have the full path. This will make loading easier later.\n",
        "- Change targets to be within a specific range. In this example, `dog` will remain at `0`, but `cat` will become `1` instead of its original value of `5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFnEoQjgs14I"
      },
      "outputs": [],
      "source": [
        "my_classes = ['dog', 'cat']\n",
        "map_class_to_id = {'dog':0, 'cat':1}\n",
        "\n",
        "filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
        "\n",
        "class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
        "filtered_pd = filtered_pd.assign(target=class_id)\n",
        "\n",
        "full_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
        "filtered_pd = filtered_pd.assign(filename=full_path)\n",
        "\n",
        "filtered_pd.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkDcBS-aJdCz"
      },
      "source": [
        "### Load the audio files and retrieve embeddings\n",
        "\n",
        "Here you'll apply the `load_wav_16k_mono` and prepare the WAV data for the model.\n",
        "\n",
        "When extracting embeddings from the WAV data, you get an array of shape `(N, 1024)`  where `N` is the number of frames that YAMNet found (one for every 0.48 seconds of audio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDT5RomaDKO"
      },
      "source": [
        "Your model will use each frame as one input. Therefore, you need to create a new column that has one frame per row. You also need to expand the labels and the `fold` column to proper reflect these new rows.\n",
        "\n",
        "The expanded `fold` column keeps the original values. You cannot mix frames because, when performing the splits, you might end up having parts of the same audio on different splits, which would make your validation and test steps less effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Rq3_PyKLtU"
      },
      "outputs": [],
      "source": [
        "filenames = filtered_pd['filename']\n",
        "targets = filtered_pd['target']\n",
        "folds = filtered_pd['fold']\n",
        "\n",
        "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsEfovDVAHGY"
      },
      "outputs": [],
      "source": [
        "def load_wav_for_map(filename, label, fold):\n",
        "  return load_wav_16k_mono(filename), label, fold\n",
        "\n",
        "main_ds = main_ds.map(load_wav_for_map)\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0tG8DBNAHcE"
      },
      "outputs": [],
      "source": [
        "# applies the embedding extraction model to a wav data\n",
        "def extract_embedding(wav_data, label, fold):\n",
        "  ''' run YAMNet to extract embedding from the wav data '''\n",
        "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
        "  num_embeddings = tf.shape(embeddings)[0]\n",
        "  return (embeddings,\n",
        "            tf.repeat(label, num_embeddings),\n",
        "            tf.repeat(fold, num_embeddings))\n",
        "\n",
        "# extract embedding\n",
        "main_ds = main_ds.map(extract_embedding).unbatch()\n",
        "main_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfPIeD0Qedk"
      },
      "source": [
        "### Split the data\n",
        "\n",
        "You will use the `fold` column to split the dataset into train, validation and test sets.\n",
        "\n",
        "ESC-50 is arranged into five uniformly-sized cross-validation `fold`s, such that clips from the same original source are always in the same `fold` - find out more in the [ESC: Dataset for Environmental Sound Classification](https://www.karolpiczak.com/papers/Piczak2015-ESC-Dataset.pdf) paper.\n",
        "\n",
        "The last step is to remove the `fold` column from the dataset since you're not going to use it during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZYvlFiVsffC"
      },
      "outputs": [],
      "source": [
        "cached_ds = main_ds.cache()\n",
        "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 4)\n",
        "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 4)\n",
        "test_ds = cached_ds.filter(lambda embedding, label, fold: fold == 5)\n",
        "\n",
        "# remove the folds column now that it's not needed anymore\n",
        "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
        "\n",
        "train_ds = train_ds.map(remove_fold_column)\n",
        "val_ds = val_ds.map(remove_fold_column)\n",
        "test_ds = test_ds.map(remove_fold_column)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5PaMwvtcAIe"
      },
      "source": [
        "## Create your model\n",
        "\n",
        "You did most of the work!\n",
        "Next, define a very simple [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) model with one hidden layer and two outputs to recognize cats and dogs from sounds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYCE0Fr1GpN3"
      },
      "outputs": [],
      "source": [
        "my_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
        "                          name='input_embedding'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(my_classes))\n",
        "], name='my_model')\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1qgH35HY0SE"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                            patience=3,\n",
        "                                            restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3sj84eOZ3pk"
      },
      "outputs": [],
      "source": [
        "history = my_model.fit(train_ds,\n",
        "                       epochs=20,\n",
        "                       validation_data=val_ds,\n",
        "                       callbacks=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAbraYKYpdoE"
      },
      "source": [
        "Let's run the `evaluate` method on the test data just to be sure there's no overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4Nh5nec3Sky"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = my_model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cid-qIrIpqHS"
      },
      "source": [
        "You did it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCKZonrJcXab"
      },
      "source": [
        "## Test your model\n",
        "\n",
        "Next, try your model on the embedding from the previous test using YAMNet only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79AFpA3_ctCF"
      },
      "outputs": [],
      "source": [
        "scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
        "result = my_model(embeddings).numpy()\n",
        "\n",
        "inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
        "print(f'The main sound is: {inferred_class}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2yleeev645r"
      },
      "source": [
        "## Save a model that can directly take a WAV file as input\n",
        "\n",
        "Your model works when you give it the embeddings as input.\n",
        "\n",
        "In a real-world scenario, you'll want to use audio data as a direct input.\n",
        "\n",
        "To do that, you will combine YAMNet with your model into a single model that you can export for other applications.\n",
        "\n",
        "To make it easier to use the model's result, the final layer will be a `reduce_mean` operation. When using this model for serving (which you will learn about later in the tutorial), you will need the name of the final layer. If you don't define one, TensorFlow will auto-define an incremental one that makes it hard to test, as it will keep changing every time you train the model. When using a raw TensorFlow operation, you can't assign a name to it. To address this issue, you'll create a custom layer that applies `reduce_mean` and call it `'classifier'`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUVCI2Suunpw"
      },
      "outputs": [],
      "source": [
        "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, axis=0, **kwargs):\n",
        "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "\n",
        "  def call(self, input):\n",
        "    return tf.math.reduce_mean(input, axis=self.axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE_Npm0nzlwc"
      },
      "outputs": [],
      "source": [
        "saved_model_path = './dogs_and_cats_yamnet'\n",
        "\n",
        "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
        "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
        "                                            trainable=False, name='yamnet')\n",
        "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
        "serving_outputs = my_model(embeddings_output)\n",
        "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
        "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
        "serving_model.save(saved_model_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-0bY5FMme1C"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(serving_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btHQDN9mqxM_"
      },
      "source": [
        "Load your saved model to verify that it works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkYVpJS72WWB"
      },
      "outputs": [],
      "source": [
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BkmvvNzq49l"
      },
      "source": [
        "And for the final test: given some sound data, does your model return the correct result?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeXtD5HO28y-"
      },
      "outputs": [],
      "source": [
        "reloaded_results = reloaded_model(testing_wav_data)\n",
        "cat_or_dog = my_classes[tf.math.argmax(reloaded_results)]\n",
        "print(f'The main sound is: {cat_or_dog}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRrOcBYTUgwn"
      },
      "source": [
        "If you want to try your new model on a serving setup, you can use the 'serving_default' signature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycC8zzDSUG2s"
      },
      "outputs": [],
      "source": [
        "serving_results = reloaded_model.signatures['serving_default'](testing_wav_data)\n",
        "cat_or_dog = my_classes[tf.math.argmax(serving_results['classifier'])]\n",
        "print(f'The main sound is: {cat_or_dog}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da7blblCHs8c"
      },
      "source": [
        "## (Optional) Some more testing\n",
        "\n",
        "The model is ready.\n",
        "\n",
        "Let's compare it to YAMNet on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDf5MASIIN1z"
      },
      "outputs": [],
      "source": [
        "test_pd = filtered_pd.loc[filtered_pd['fold'] == 5]\n",
        "row = test_pd.sample(1)\n",
        "filename = row['filename'].item()\n",
        "print(filename)\n",
        "waveform = load_wav_16k_mono(filename)\n",
        "print(f'Waveform values: {waveform}')\n",
        "_ = plt.plot(waveform)\n",
        "\n",
        "display.Audio(waveform, rate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYUzFxYJIcE1"
      },
      "outputs": [],
      "source": [
        "# Run the model, check the output.\n",
        "scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "class_scores = tf.reduce_mean(scores, axis=0)\n",
        "top_class = tf.math.argmax(class_scores)\n",
        "inferred_class = class_names[top_class]\n",
        "top_score = class_scores[top_class]\n",
        "print(f'[YAMNet] The main sound is: {inferred_class} ({top_score})')\n",
        "\n",
        "reloaded_results = reloaded_model(waveform)\n",
        "your_top_class = tf.math.argmax(reloaded_results)\n",
        "your_inferred_class = my_classes[your_top_class]\n",
        "class_probabilities = tf.nn.softmax(reloaded_results, axis=-1)\n",
        "your_top_score = class_probabilities[your_top_class]\n",
        "print(f'[Your model] The main sound is: {your_inferred_class} ({your_top_score})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Tsym8Rq-0V"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You have created a model that can classify sounds from dogs or cats. With the same idea and a different dataset you can try, for example, building an [acoustic identifier of birds](https://www.kaggle.com/c/birdclef-2021/) based on their singing.\n",
        "\n",
        "Share your project with the TensorFlow team on social media!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transfer_learning_audio.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
"## Generate a TensorFlow Lite Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHe-Wv47rhm8"
      },
      "source": [
        "### 1. Generate Models with or without Quantization\n",
        "We now have an acceptably accurate model. We'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
        "\n",
        "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of a model is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization). It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
        "\n",
        "In the following cell, we'll convert the model twice: once with quantization, once without."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1muAoUm8lSXL",
        "outputId": "aad8259e-df57-4f03-da77-d490e5609d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2488"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      {
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([x_train[i].reshape(1, 1)])\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "### 2. Compare Model Performance\n",
        "\n",
        "To prove these models are accurate even after conversion and quantization, we'll compare their predictions and loss on our test dataset.\n",
        "\n",
        "**Helper functions**\n",
        "\n",
        "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "NKtmxEhko1S1"
      },
      "outputs": [],
      "source": [
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test.copy()\n",
        "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
        "  x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model,\n",
        "                                    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.BUILTIN_REF)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "  \n",
        "  # Invoke the interpreter\n",
        "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
        "  for i in range(len(x_test_)):\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "  \n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def evaluate_tflite(tflite_model, x_test, y_true):\n",
        "  global model\n",
        "  y_pred = predict_tflite(tflite_model, x_test)\n",
        "  loss_function = tf.keras.losses.get(model.loss)\n",
        "  loss = loss_function(y_true, y_pred).numpy()\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLZLY0D4gl6U"
      },
      "source": [
        "**1. Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RS3zni1gkrt"
      },
      "outputs": [],
      "source": [
        "# Calculate predictions\n",
        "y_test_pred_tf = model.predict(x_test)\n",
        "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
        "y_test_pred_tflite = predict_tflite(model_tflite, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "-J7IKlXiYVPz",
        "outputId": "24017e5e-7672-460c-8b76-c0ed71f3ec27"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare predictions\n",
        "plt.clf()\n",
        "plt.title('Comparison of various models against actual values')\n",
        "plt.plot(x_test, y_test, 'bo', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred_tf, 'ro', label='TF predictions')\n",
        "plt.plot(x_test, y_test_pred_no_quant_tflite, 'bx', label='TFLite predictions')\n",
        "plt.plot(x_test, y_test_pred_tflite, 'gx', label='TFLite quantized predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7vlfJqbiZMU"
      },
      "source": [
        "**2. Loss (MSE/Mean Squared Error)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpHifyGZRhw8"
      },
      "outputs": [],
      "source": [
        "# Calculate loss\n",
        "loss_tf, _ = model.evaluate(x_test, y_test, verbose=0)\n",
        "loss_no_quant_tflite = evaluate_tflite(model_no_quant_tflite, x_test, y_test)\n",
        "loss_tflite = evaluate_tflite(model_tflite, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "g3HLT0UOjTY_",
        "outputId": "0c1c279a-96bd-4e8d-8a65-6a071376825b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss/MSE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TensorFlow</th>\n",
              "      <td>0.0102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow Lite</th>\n",
              "      <td>0.0102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow Lite Quantized</th>\n",
              "      <td>0.0108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Loss/MSE\n",
              "Model                              \n",
              "TensorFlow                   0.0102\n",
              "TensorFlow Lite              0.0102\n",
              "TensorFlow Lite Quantized    0.0108"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compare loss\n",
        "df = pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", loss_tf],\n",
        "     [\"TensorFlow Lite\", loss_no_quant_tflite],\n",
        "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
        "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Vjw7VckLu1"
      },
      "source": [
        "**3. Size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEXiJ8dFkL2R"
      },
      "outputs": [],
      "source": [
        "# Calculate size\n",
        "size_tf = os.path.getsize(MODEL_TF)\n",
        "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
        "size_tflite = os.path.getsize(MODEL_TFLITE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "8DdsCaL7kL4u",
        "outputId": "9644f10d-0914-4939-b596-facb90e4b961"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TensorFlow</th>\n",
              "      <td>4096 bytes</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow Lite</th>\n",
              "      <td>2788 bytes</td>\n",
              "      <td>(reduced by 1308 bytes)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow Lite Quantized</th>\n",
              "      <td>2488 bytes</td>\n",
              "      <td>(reduced by 300 bytes)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Size                         \n",
              "Model                                                          \n",
              "TensorFlow                  4096 bytes                         \n",
              "TensorFlow Lite            2788 bytes   (reduced by 1308 bytes)\n",
              "TensorFlow Lite Quantized   2488 bytes   (reduced by 300 bytes)"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compare size\n",
        "pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
        "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
        "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
        "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXdmfo7imGMB"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1LVMA2nkM_l"
      },
      "source": [
        "We can see from the predictions (graph) and loss (table) that the original TF model, the TFLite model, and the quantized TFLite model are all close enough to be indistinguishable - even though they differ in size (table). This implies that the quantized (smallest) model is ready to use!\n",
        "\n",
        "*Note: The quantized (integer) TFLite model is just 300 bytes smaller than the original (float) TFLite model - a tiny reduction in size! This is because the model is already so small that quantization has little effect. Complex models with more weights, can have upto a 4x reduction in size!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFmDL7pv2L"
      },
      "source": [
        "## Generate a TensorFlow Lite for Microcontrollers Model\n",
        "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1FB4ieeg0lw",
        "outputId": "c25b75c6-a28d-47b1-9b3a-b7ba821ee310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRy0ZyMhQOX"
      },
      "source": [
        "## Deploy to a Microcontroller\n",
        "\n",
        "Follow the instructions in the [hello_world](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world) README.md for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview) to deploy this model on a specific microcontroller.\n",
        "\n",
        "**Reference Model:** If you have not modified this notebook, you can follow the instructions as is, to deploy the model. Refer to the [`hello_world/train/models`](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/models) directory to access the models generated in this notebook.\n",
        "\n",
        "**New Model:** If you have generated a new model, then update the values assigned to the variables defined in [`hello_world/model.cc`](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/model.cc) with values displayed after running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4-WhtGpvb-E",
        "outputId": "4c7925a5-4cf3-4f7a-fcbc-c8c2857423ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unsigned char g_model[] = {\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x14, 0x00, 0x20, 0x00,\n",
            "  0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x98, 0x00, 0x00, 0x00, 0xc8, 0x00, 0x00, 0x00, 0x1c, 0x03, 0x00, 0x00,\n",
            "  0x2c, 0x03, 0x00, 0x00, 0x30, 0x09, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x60, 0xf7, 0xff, 0xff,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76,\n",
            "  0x65, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76,\n",
            "  0x69, 0x6e, 0x67, 0x5f, 0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xbc, 0xff, 0xff, 0xff,\n",
            "  0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x34, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x76, 0xfd, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x5f,\n",
            "  0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74,\n",
            "  0x69, 0x6d, 0x65, 0x5f, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x50, 0x02, 0x00, 0x00, 0x48, 0x02, 0x00, 0x00,\n",
            "  0x34, 0x02, 0x00, 0x00, 0xdc, 0x01, 0x00, 0x00, 0x8c, 0x01, 0x00, 0x00,\n",
            "  0x6c, 0x01, 0x00, 0x00, 0x5c, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
            "  0x34, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0xfa, 0xfd, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x31, 0x2e, 0x35, 0x2e, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x84, 0xfd, 0xff, 0xff,\n",
            "  0x88, 0xfd, 0xff, 0xff, 0x8c, 0xfd, 0xff, 0xff, 0x22, 0xfe, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x21, 0xa5, 0x8b, 0xca,\n",
            "  0x5e, 0x1d, 0xce, 0x42, 0x9d, 0xce, 0x1f, 0xb0, 0xdf, 0x54, 0x2f, 0x81,\n",
            "  0x3e, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00,\n",
            "  0xee, 0xfc, 0x00, 0xec, 0x05, 0x17, 0xef, 0xec, 0xe6, 0xf8, 0x03, 0x01,\n",
            "  0x00, 0xfa, 0xf8, 0xf5, 0xdc, 0xeb, 0x27, 0x14, 0xf1, 0xde, 0xe2, 0xdb,\n",
            "  0xf0, 0xde, 0x31, 0x06, 0x02, 0xe6, 0xee, 0xf9, 0x00, 0x16, 0x07, 0xe0,\n",
            "  0xfe, 0xff, 0xe9, 0x06, 0xe7, 0xef, 0x81, 0x1b, 0x18, 0xea, 0xc9, 0x01,\n",
            "  0x0f, 0x00, 0xda, 0xf7, 0x0e, 0xec, 0x13, 0x1f, 0x04, 0x13, 0xb4, 0xe6,\n",
            "  0xfd, 0x06, 0xb9, 0xe0, 0x0d, 0xec, 0xf0, 0xde, 0xeb, 0xf7, 0x05, 0x26,\n",
            "  0x1a, 0xe4, 0x6f, 0x1a, 0xea, 0x1e, 0x35, 0xdf, 0x1a, 0xf3, 0xf1, 0x19,\n",
            "  0x0f, 0x03, 0x1b, 0xe1, 0xde, 0x13, 0xf6, 0x19, 0xff, 0xf6, 0x1b, 0x18,\n",
            "  0xf0, 0x1c, 0xda, 0x1b, 0x1b, 0x20, 0xe5, 0x1a, 0xf5, 0xff, 0x96, 0x0b,\n",
            "  0x00, 0x01, 0xcd, 0xde, 0x0d, 0xf6, 0x16, 0xe3, 0xed, 0xfc, 0x0e, 0xe9,\n",
            "  0xfa, 0xeb, 0x5c, 0xfc, 0x1d, 0x02, 0x5b, 0xe2, 0xe1, 0xf5, 0x15, 0xec,\n",
            "  0xf4, 0x00, 0x13, 0x05, 0xec, 0x0c, 0x1d, 0x14, 0x0e, 0xe7, 0x0b, 0xf4,\n",
            "  0x19, 0x00, 0xd7, 0x05, 0x27, 0x02, 0x15, 0xea, 0xea, 0x02, 0x9b, 0x00,\n",
            "  0x0c, 0xfa, 0xe8, 0xea, 0xfd, 0x00, 0x14, 0xfd, 0x0b, 0x02, 0xef, 0xee,\n",
            "  0x06, 0xee, 0x01, 0x0d, 0x06, 0xe6, 0xf7, 0x11, 0xf7, 0x09, 0xf8, 0xf1,\n",
            "  0x21, 0xff, 0x0e, 0xf3, 0xec, 0x12, 0x26, 0x1d, 0xf2, 0xe9, 0x28, 0x18,\n",
            "  0xe0, 0xfb, 0xf3, 0xf4, 0x05, 0x1d, 0x1d, 0xfb, 0xfd, 0x1e, 0xfc, 0x11,\n",
            "  0xe8, 0x07, 0x09, 0x03, 0x12, 0xf2, 0x36, 0xfb, 0xdc, 0x1c, 0xf9, 0xef,\n",
            "  0xf3, 0xe7, 0x6f, 0x0c, 0x1d, 0x00, 0x45, 0xfd, 0x0e, 0xf0, 0x0b, 0x19,\n",
            "  0x1a, 0xfa, 0xe0, 0x19, 0x1f, 0x13, 0x36, 0x1c, 0x12, 0xeb, 0x3b, 0x0c,\n",
            "  0xb4, 0xcb, 0xe6, 0x13, 0xfa, 0xeb, 0xf1, 0x06, 0x1c, 0xfa, 0x18, 0xe5,\n",
            "  0xeb, 0xcb, 0x0c, 0xf4, 0x4a, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x75, 0x1c, 0x11, 0xe1, 0x0c, 0x81, 0xa5, 0x42,\n",
            "  0xfe, 0xd5, 0xd4, 0xb2, 0x61, 0x78, 0x19, 0xdf, 0x66, 0xff, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x77, 0x0b, 0x00, 0x00, 0x53, 0xf6, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x77, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xd3, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x72, 0x21, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x2f, 0x07, 0x00, 0x00,\n",
            "  0x67, 0xf5, 0xff, 0xff, 0x34, 0xf0, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xb2, 0xff, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xb5, 0x04, 0x00, 0x00, 0x78, 0x0a, 0x00, 0x00,\n",
            "  0x2d, 0x06, 0x00, 0x00, 0x71, 0xf8, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x9a, 0x0a, 0x00, 0x00, 0xfe, 0xf7, 0xff, 0xff, 0x0e, 0x05, 0x00, 0x00,\n",
            "  0xd4, 0x09, 0x00, 0x00, 0x47, 0xfe, 0xff, 0xff, 0xb6, 0x04, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xac, 0xf7, 0xff, 0xff, 0x4b, 0xf9, 0xff, 0xff,\n",
            "  0x4a, 0x05, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x8c, 0xef, 0xff, 0xff, 0x84, 0xff, 0xff, 0xff, 0x88, 0xff, 0xff, 0xff,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52, 0x20, 0x43, 0x6f, 0x6e,\n",
            "  0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x14, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0xdc, 0x00, 0x00, 0x00,\n",
            "  0xe0, 0x00, 0x00, 0x00, 0xe4, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x84, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x96, 0xff, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xca, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x08, 0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0xba, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x16, 0x00, 0x00, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00,\n",
            "  0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x4c, 0x04, 0x00, 0x00,\n",
            "  0xd0, 0x03, 0x00, 0x00, 0x68, 0x03, 0x00, 0x00, 0x0c, 0x03, 0x00, 0x00,\n",
            "  0x98, 0x02, 0x00, 0x00, 0x24, 0x02, 0x00, 0x00, 0xb0, 0x01, 0x00, 0x00,\n",
            "  0x24, 0x01, 0x00, 0x00, 0x98, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0xf0, 0xfb, 0xff, 0xff, 0x18, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x54, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xdc, 0xfb, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x4a, 0xce, 0x0a, 0x3c, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x34, 0x84, 0x85, 0x3f, 0x01, 0x00, 0x00, 0x00, 0xc5, 0x02, 0x8f, 0xbf,\n",
            "  0x1e, 0x00, 0x00, 0x00, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c,\n",
            "  0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43,\n",
            "  0x61, 0x6c, 0x6c, 0x3a, 0x30, 0x5f, 0x69, 0x6e, 0x74, 0x38, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x80, 0xfc, 0xff, 0xff, 0x18, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x54, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x64, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x6c, 0xfc, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x93, 0xd0, 0xc0, 0x3b, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xc2, 0x0f, 0xc0, 0x3f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x74, 0x66, 0x6c, 0x2e, 0x66, 0x75, 0x6c, 0x6c,\n",
            "  0x79, 0x5f, 0x63, 0x6f, 0x6e, 0x6e, 0x65, 0x63, 0x74, 0x65, 0x64, 0x31,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x08, 0xfd, 0xff, 0xff, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x58, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x64, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0xf4, 0xfc, 0xff, 0xff,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xe0, 0xdb, 0x47, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x04, 0x14, 0x47, 0x40,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
            "  0x74, 0x66, 0x6c, 0x2e, 0x66, 0x75, 0x6c, 0x6c, 0x79, 0x5f, 0x63, 0x6f,\n",
            "  0x6e, 0x6e, 0x65, 0x63, 0x74, 0x65, 0x64, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x02, 0xfe, 0xff, 0xff,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x48, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x50, 0x00, 0x00, 0x00, 0x6c, 0xfd, 0xff, 0xff,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xfb, 0x4b, 0x0b, 0x3c,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x40, 0x84, 0x4b, 0x3f, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x63, 0x35, 0x8a, 0xbf, 0x0d, 0x00, 0x00, 0x00, 0x73, 0x74, 0x64, 0x2e,\n",
            "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x32, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x72, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x48, 0x00, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x50, 0x00, 0x00, 0x00,\n",
            "  0xdc, 0xfd, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x60, 0x01, 0x4f, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x47, 0x6d, 0xb3, 0x3f,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x5d, 0x63, 0xcd, 0xbf, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x74, 0x64, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74,\n",
            "  0x31, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0xe2, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x48, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x50, 0x00, 0x00, 0x00, 0x4c, 0xfe, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xd5, 0x6b, 0x8a, 0x3b, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xab, 0x49, 0x01, 0x3f, 0x01, 0x00, 0x00, 0x00, 0xfd, 0x56, 0x09, 0xbf,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x73, 0x74, 0x64, 0x2e, 0x63, 0x6f, 0x6e, 0x73,\n",
            "  0x74, 0x61, 0x6e, 0x74, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x52, 0xff, 0xff, 0xff,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x34, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x02, 0x3c, 0x00, 0x00, 0x00, 0x44, 0xff, 0xff, 0xff,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x28, 0xb3, 0xd9, 0x38, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x2f, 0x62, 0x69, 0x61, 0x73,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0xaa, 0xff, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x38, 0x00, 0x00, 0x00,\n",
            "  0x9c, 0xff, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xdd, 0x9b, 0x21, 0x39, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x33, 0x2f, 0x62, 0x69, 0x61, 0x73,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x14, 0x00, 0x13, 0x00, 0x0c, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n",
            "  0x48, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xf4, 0xd4, 0x51, 0x38, 0x0c, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73,\n",
            "  0x65, 0x5f, 0x34, 0x2f, 0x62, 0x69, 0x61, 0x73, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x1c, 0x00,\n",
            "  0x18, 0x00, 0x17, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x2c, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x84, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x14, 0x00,\n",
            "  0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x5d, 0x4f, 0xc9, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x0e, 0x86, 0xc8, 0x40,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f, 0x64, 0x65, 0x66, 0x61,\n",
            "  0x75, 0x6c, 0x74, 0x5f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x5f,\n",
            "  0x69, 0x6e, 0x70, 0x75, 0x74, 0x3a, 0x30, 0x5f, 0x69, 0x6e, 0x74, 0x38,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xd8, 0xff, 0xff, 0xff,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06,\n",
            "  0x0c, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x72, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x72,\n",
            "  0x0c, 0x00, 0x10, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09\n",
            "};\n",
            "unsigned int g_model_len = 2488;\n"
          ]
        }
      ],
      "source": [
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train_hello_world_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "22cb1d09959a40fdc50ccd77b5464bb60602aea13b58d7f13d7eaffcd0bc7c7d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

